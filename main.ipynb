{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ad4fb6",
   "metadata": {},
   "source": [
    "### Previsão de Mortes Neonatal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ff8a3",
   "metadata": {},
   "source": [
    "Neste projeto, vamos utilizar dados públicos do SINASC (Sistema de Nascidos Vivos) e do SIM (Sistema de Mortalidade) para construir modelos de aprendizado de máquina capazes de prever o risco de morte neonatal (até 28 dias após o nascimento)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbade0e",
   "metadata": {},
   "source": [
    "*Alunos:*\n",
    "- Júlia Moraes\n",
    "- Luiz Eduardo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a70808",
   "metadata": {},
   "source": [
    "Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bdbfee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a130723",
   "metadata": {},
   "source": [
    "#### 1. Tratamentos básico dos dados para ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905541bc",
   "metadata": {},
   "source": [
    "##### 1.1 Construindo matriz X e vetor y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9242ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sinasc_balanceado.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc8bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados númericos\n",
    "num_cols = ['idade_mae', 'peso', 'semanas_gestacao', 'num_gestacao',\n",
    "            'partos_normais', 'partos_cesareos', 'mes_inicio_prenatal', 'qntd_filvivos', 'qntd_filmortos']\n",
    "\n",
    "# dados ordinais\n",
    "ord_cols = ['consultas_prenatal', 'indice_kotelchuck', 'escolaridade_mae']\n",
    "\n",
    "# dados categóricos\n",
    "cat_cols = ['tipo_gravidez', 'tipo_parto', 'parto_induzido', 'cesarea_antes',\n",
    "            'racacor_mae', 'racacor_bebe', 'paridade', 'anomalia_identificada',\n",
    "            'doenca_epidemiologicas', 'doenca_nova',\n",
    "            'prenatal_inadequado', 'poucas_consultas', 'prenatal_tardio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a409df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar 9 ou outros ignorados em NaN\n",
    "df.replace(9, pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77bf2e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline de pré-processamento\n",
    "\n",
    "# Numéricas: imputar média e padronizar\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # valores vazios vira média\n",
    "    ('scaler', StandardScaler()) # normaliza\n",
    "])\n",
    "\n",
    "# Ordinais: imputar mais frequente e codificar como dummies\n",
    "ord_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # valores vazios vira moda\n",
    "])\n",
    "\n",
    "# Categóricas: imputar mais frequente e codificar dummies\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # valores vazios vira moda\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # codifica dummies\n",
    "]) # exemplo: tipo_parto_vaginal, tipo_parto_cesarea recebe 0 ou 1 \n",
    "\n",
    "# Combinar\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('ord', ord_transformer, ord_cols),\n",
    "        ('cat', cat_transformer, cat_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81371fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['obitos_1m']\n",
    "X = df.drop(columns=['obitos_1m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "110ff8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos nas colunas numéricas:\n",
      "idade_mae: 2\n",
      "peso: 29\n",
      "semanas_gestacao: 585\n",
      "num_gestacao: 1621\n",
      "partos_normais: 2214\n",
      "partos_cesareos: 2237\n",
      "mes_inicio_prenatal: 2220\n",
      "qntd_filvivos: 1714\n",
      "qntd_filmortos: 2432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julja\\AppData\\Local\\Temp\\ipykernel_14356\\1250505372.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X = X.replace({pd.NA: np.nan})\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores nulos nas colunas numéricas\n",
    "print(\"Valores nulos nas colunas numéricas:\")\n",
    "for col in num_cols:\n",
    "    if col in X.columns:\n",
    "        print(f\"{col}: {X[col].isnull().sum()}\")\n",
    "\n",
    "# Substituir pd.NA por np.nan para compatibilidade com sklearn\n",
    "X = X.replace({pd.NA: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a6e07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fcf5ea",
   "metadata": {},
   "source": [
    "##### 1.2 Número de amostras e parametros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5829c643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras (N): 44958\n",
      "Número de parâmetros (p): 46\n"
     ]
    }
   ],
   "source": [
    "N, p = X_processed.shape\n",
    "\n",
    "print(f\"Número de amostras (N): {N}\")\n",
    "print(f\"Número de parâmetros (p): {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d350e6",
   "metadata": {},
   "source": [
    "##### 1.3 Separar em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7f5b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede81c06",
   "metadata": {},
   "source": [
    "#### 2. REDES NEURAIS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
